"""
M3 Agent System v6.0 - Background Tasks Manager

åå°ä»»åŠ¡ç®¡ç†å™¨ï¼ˆä¼˜åŒ–æ—¶é—´å®‰æ’ï¼Œé¿å…å¯åŠ¨å†²çªï¼‰ï¼š
- å¯åŠ¨å15åˆ†é’Ÿï¼šå†…å­˜é¢„åŠ è½½ï¼ˆå·¥å…·æ± +æ¨¡å‹ï¼‰
- é¢„åŠ è½½åç«‹å³ï¼šAPIå’Œå·¥å…·å†…éƒ¨æ£€æµ‹ â†’ æ±‡æŠ¥åˆ°æ§åˆ¶é¢æ¿
- ä¹‹åæ¯30åˆ†é’Ÿï¼šAPIå’Œå·¥å…·æ£€æµ‹
- å¯åŠ¨å30åˆ†é’Ÿï¼šæ€§èƒ½æ£€æµ‹ï¼ˆæ¨¡å‹æ€§èƒ½æµ‹è¯•ï¼‰
- ä¹‹åæ¯30åˆ†é’Ÿï¼šæ€§èƒ½æ£€æµ‹

æ—¶é—´çº¿ï¼š
T+0:    ç³»ç»Ÿå¯åŠ¨ï¼ˆè½»é‡çº§ï¼Œæ— é¢„åŠ è½½ï¼‰
T+15:   å†…å­˜é¢„åŠ è½½ + API/å·¥å…·æ£€æµ‹
T+30:   æ€§èƒ½æ£€æµ‹
T+45:   API/å·¥å…·æ£€æµ‹
T+60:   æ€§èƒ½æ£€æµ‹
T+75:   API/å·¥å…·æ£€æµ‹
...
"""
import asyncio
import logging
import time
from datetime import datetime
from typing import Dict, Any, Optional
import httpx
import os

logger = logging.getLogger("m3_agent")


class BackgroundTasksManager:
    """åå°ä»»åŠ¡ç®¡ç†å™¨ v6.0"""
    
    def __init__(self):
        self.started_at = datetime.now()
        self.startup_time = time.time()
        
        # çŠ¶æ€æ ‡å¿—
        self.preload_completed = False
        self.preload_time = None
        
        # æ£€æµ‹ç»“æœç¼“å­˜
        self.last_api_check = None
        self.last_performance_test = None
        self.health_status = {
            "tools": {},
            "apis": {},
            "models": {},
            "browser_pool": {}
        }
        
        # ä»»åŠ¡å¼•ç”¨
        self.tasks = {}
    
    async def start(self):
        """å¯åŠ¨æ‰€æœ‰åå°ä»»åŠ¡"""
        logger.info("=" * 80)
        logger.info("ğŸš€ Starting Background Tasks Manager v6.0")
        logger.info("=" * 80)
        logger.info("ğŸ“… Schedule:")
        logger.info("   T+15min: Memory Preload + API/Tool Check")
        logger.info("   T+30min: Performance Test")
        logger.info("   Then every 30min alternating (15min offset)")
        logger.info("=" * 80)
        
        # å¯åŠ¨é¢„åŠ è½½ä»»åŠ¡ï¼ˆ15åˆ†é’Ÿåï¼‰
        self.tasks['preload'] = asyncio.create_task(
            self._delayed_preload_task()
        )
        
        # å¯åŠ¨API/å·¥å…·æ£€æµ‹ä»»åŠ¡ï¼ˆ15åˆ†é’Ÿåé¦–æ¬¡ï¼Œä¹‹åæ¯30åˆ†é’Ÿï¼‰
        self.tasks['api_check'] = asyncio.create_task(
            self._api_tool_check_task()
        )
        
        # å¯åŠ¨æ€§èƒ½æ£€æµ‹ä»»åŠ¡ï¼ˆ30åˆ†é’Ÿåé¦–æ¬¡ï¼Œä¹‹åæ¯30åˆ†é’Ÿï¼‰
        self.tasks['performance'] = asyncio.create_task(
            self._performance_test_task()
        )
        
        logger.info("âœ… Background tasks scheduled")
    
    async def stop(self):
        """åœæ­¢æ‰€æœ‰åå°ä»»åŠ¡"""
        logger.info("Stopping background tasks...")
        for name, task in self.tasks.items():
            if not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
        logger.info("âœ… All background tasks stopped")
    
    # ============================================
    # å†…å­˜é¢„åŠ è½½
    # ============================================
    
    async def _delayed_preload_task(self):
        """å»¶è¿Ÿé¢„åŠ è½½ä»»åŠ¡ï¼ˆå¯åŠ¨å15åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼‰"""
        try:
            logger.info("â° Memory preload scheduled in 15 minutes...")
            await asyncio.sleep(900)  # 15åˆ†é’Ÿ
            
            logger.info("=" * 80)
            logger.info("ğŸ“¦ Starting Memory Preload (T+15min)")
            logger.info("=" * 80)
            
            await self._preload_memory()
            
            self.preload_completed = True
            self.preload_time = datetime.now()
            
            logger.info("=" * 80)
            logger.info(f"âœ… Memory Preload Complete at {self.preload_time.strftime('%H:%M:%S')}")
            logger.info("=" * 80)
            
        except asyncio.CancelledError:
            logger.info("Preload task cancelled")
        except Exception as e:
            logger.error(f"Preload task failed: {e}", exc_info=True)
    
    async def _preload_memory(self):
        """é¢„åŠ è½½å†…å­˜ï¼ˆå·¥å…·æ± +æ¨¡å‹ï¼‰"""
        try:
            # 1. é¢„åŠ è½½æµè§ˆå™¨æ± ï¼ˆå·²åœ¨startupæ—¶åŠ è½½ï¼Œè¿™é‡Œæ£€æŸ¥çŠ¶æ€ï¼‰
            logger.info("ğŸŒ Checking browser pool...")
            from app.core.browser_pool import get_browser_pool
            browser_pool = get_browser_pool()
            if browser_pool and browser_pool._started:
                logger.info("   âœ… Browser pool already loaded")
                self.health_status["browser_pool"]["status"] = "loaded"
            else:
                logger.warning("   âš ï¸ Browser pool not started")
                self.health_status["browser_pool"]["status"] = "not_started"
            
            # 2. é¢„åŠ è½½Whisperæ¨¡å‹
            logger.info("ğŸ¤ Preloading Whisper model...")
            try:
                from app.tools.speech_recognition_tool import SpeechRecognitionTool
                # åˆ›å»ºå®ä¾‹ä¼šè§¦å‘é¢„åŠ è½½
                whisper_tool = SpeechRecognitionTool(preload_model=True, model_size="small")
                logger.info("   âœ… Whisper model loaded (small)")
                self.health_status["models"]["whisper"] = "loaded"
            except Exception as e:
                logger.warning(f"   âš ï¸ Whisper preload failed: {e}")
                self.health_status["models"]["whisper"] = f"failed: {e}"
            
            # 3. é¢„åŠ è½½OCRæ¨¡å‹
            logger.info("ğŸ” Preloading OCR models...")
            try:
                from app.tools.image_ocr import ImageOCRTool
                ocr_tool = ImageOCRTool()
                logger.info("   âœ… OCR models loaded (EasyOCR)")
                self.health_status["models"]["ocr"] = "loaded"
            except Exception as e:
                logger.warning(f"   âš ï¸ OCR preload failed: {e}")
                self.health_status["models"]["ocr"] = f"failed: {e}"
            
            # 4. é¢„åŠ è½½å›¾åƒåˆ†ææ¨¡å‹
            logger.info("ğŸ–¼ï¸ Preloading image analysis models...")
            try:
                from app.tools.image_analysis import ImageAnalysisTool
                image_tool = ImageAnalysisTool()
                logger.info("   âœ… Image analysis models loaded (Haar Cascade)")
                self.health_status["models"]["image_analysis"] = "loaded"
            except Exception as e:
                logger.warning(f"   âš ï¸ Image analysis preload failed: {e}")
                self.health_status["models"]["image_analysis"] = f"failed: {e}"
            
            # æ¨é€åˆ°èŠå¤©å®¤
            await self._send_system_message(
                "âœ… å†…å­˜é¢„åŠ è½½å®Œæˆ\n" +
                f"- æµè§ˆå™¨æ± : {self.health_status['browser_pool'].get('status', 'unknown')}\n" +
                f"- Whisper: {self.health_status['models'].get('whisper', 'unknown')}\n" +
                f"- OCR: {self.health_status['models'].get('ocr', 'unknown')}\n" +
                f"- å›¾åƒåˆ†æ: {self.health_status['models'].get('image_analysis', 'unknown')}",
                metadata={"type": "memory_preload", "status": self.health_status}
            )
            
        except Exception as e:
            logger.error(f"Memory preload failed: {e}", exc_info=True)
            await self._send_system_message(
                f"âŒ å†…å­˜é¢„åŠ è½½å¤±è´¥: {e}",
                metadata={"type": "error"}
            )
    
    # ============================================
    # APIå’Œå·¥å…·æ£€æµ‹
    # ============================================
    
    async def _api_tool_check_task(self):
        """APIå’Œå·¥å…·æ£€æµ‹ä»»åŠ¡ï¼ˆ15åˆ†é’Ÿåé¦–æ¬¡ï¼Œä¹‹åæ¯30åˆ†é’Ÿï¼‰"""
        try:
            # é¦–æ¬¡ç­‰å¾…15åˆ†é’Ÿï¼ˆä¸é¢„åŠ è½½åŒæ—¶ï¼‰
            logger.info("â° API/Tool check scheduled in 15 minutes...")
            await asyncio.sleep(900)  # 15åˆ†é’Ÿ
            
            # ç­‰å¾…é¢„åŠ è½½å®Œæˆ
            await asyncio.sleep(10)  # é¢„åŠ è½½å10ç§’æ‰§è¡Œæ£€æµ‹
            
            while True:
                try:
                    logger.info("=" * 80)
                    logger.info("ğŸ”Œ API/Tool Health Check")
                    logger.info("=" * 80)
                    
                    await self._check_api_and_tools()
                    
                    logger.info("=" * 80)
                    logger.info(f"âœ… API/Tool Check Complete at {datetime.now().strftime('%H:%M:%S')}")
                    logger.info("=" * 80)
                    
                except Exception as e:
                    logger.error(f"API/Tool check failed: {e}")
                
                # ç­‰å¾…30åˆ†é’Ÿ
                await asyncio.sleep(1800)
                
        except asyncio.CancelledError:
            logger.info("API/Tool check task cancelled")
    
    async def _check_api_and_tools(self):
        """æ£€æŸ¥APIå’Œå·¥å…·çŠ¶æ€"""
        check_result = {
            "timestamp": datetime.now().isoformat(),
            "tools": {},
            "apis": {},
            "summary": {}
        }
        
        try:
            # 1. æ£€æŸ¥15ä¸ªå·¥å…·
            logger.info("ğŸ”§ Checking tools...")
            from app.core.startup import initialize_browser_pool_and_tools
            try:
                _, tools = initialize_browser_pool_and_tools()
                check_result["tools"]["count"] = len(tools)
                check_result["tools"]["names"] = [tool.name for tool in tools]
                check_result["tools"]["status"] = "available"
                logger.info(f"   âœ… {len(tools)} tools available")
                
                # æµ‹è¯•å…³é”®å·¥å…·
                tool_tests = {}
                for tool in tools[:3]:  # æµ‹è¯•å‰3ä¸ªå·¥å…·
                    try:
                        # ç®€å•æµ‹è¯•ï¼šæ£€æŸ¥å·¥å…·æ˜¯å¦æœ‰å¿…è¦çš„æ–¹æ³•
                        if hasattr(tool, '_run') and hasattr(tool, 'name'):
                            tool_tests[tool.name] = "ok"
                        else:
                            tool_tests[tool.name] = "missing_methods"
                    except Exception as e:
                        tool_tests[tool.name] = f"error: {e}"
                
                check_result["tools"]["tests"] = tool_tests
                
            except Exception as e:
                logger.warning(f"   âŒ Tools check failed: {e}")
                check_result["tools"]["status"] = "error"
                check_result["tools"]["error"] = str(e)
            
            # 2. æ£€æŸ¥Fleet API
            logger.info("ğŸš¢ Checking Fleet API...")
            try:
                from app.api.fleet_api import router as fleet_router
                check_result["apis"]["fleet"] = "available"
                logger.info("   âœ… Fleet API available")
            except Exception as e:
                check_result["apis"]["fleet"] = f"error: {e}"
                logger.warning(f"   âŒ Fleet API: {e}")
            
            # 3. æ£€æŸ¥LangGraph API
            logger.info("ğŸ”— Checking LangGraph API...")
            try:
                from app.api.langgraph_adapter import router as langgraph_router
                check_result["apis"]["langgraph"] = "available"
                logger.info("   âœ… LangGraph API available")
            except Exception as e:
                check_result["apis"]["langgraph"] = f"error: {e}"
                logger.warning(f"   âŒ LangGraph API: {e}")
            
            # 4. æ£€æŸ¥LLMè¿æ¥
            logger.info("ğŸ¤– Checking LLM connection...")
            llm_base_url = os.getenv("LLM_BASE_URL", "http://192.168.9.125:8000/v1")
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(f"{llm_base_url}/models")
                    if response.status_code == 200:
                        data = response.json()
                        models = data.get("data", [])
                        check_result["apis"]["llm"] = {
                            "status": "connected",
                            "models_count": len(models),
                            "models": [m.get("id") for m in models[:3]]
                        }
                        logger.info(f"   âœ… LLM connected ({len(models)} models)")
                    else:
                        check_result["apis"]["llm"] = {"status": "error", "code": response.status_code}
                        logger.warning(f"   âš ï¸ LLM returned {response.status_code}")
            except Exception as e:
                check_result["apis"]["llm"] = {"status": "error", "error": str(e)}
                logger.warning(f"   âŒ LLM connection failed: {e}")
            
            # 5. ç”Ÿæˆæ‘˜è¦
            tools_ok = check_result["tools"].get("status") == "available"
            fleet_ok = check_result["apis"].get("fleet") == "available"
            langgraph_ok = check_result["apis"].get("langgraph") == "available"
            llm_ok = check_result["apis"].get("llm", {}).get("status") == "connected"
            
            check_result["summary"] = {
                "tools": "âœ…" if tools_ok else "âŒ",
                "fleet_api": "âœ…" if fleet_ok else "âŒ",
                "langgraph_api": "âœ…" if langgraph_ok else "âŒ",
                "llm": "âœ…" if llm_ok else "âŒ",
                "overall": "healthy" if all([tools_ok, fleet_ok, langgraph_ok, llm_ok]) else "degraded"
            }
            
            self.last_api_check = check_result
            self.health_status["tools"] = check_result["tools"]
            self.health_status["apis"] = check_result["apis"]
            
            # æ¨é€åˆ°èŠå¤©å®¤å’Œæ§åˆ¶é¢æ¿
            await self._send_system_message(
                "ğŸ”Œ API/å·¥å…·æ£€æµ‹å®Œæˆ\n" +
                f"- å·¥å…·: {check_result['summary']['tools']} ({check_result['tools'].get('count', 0)}ä¸ª)\n" +
                f"- Fleet API: {check_result['summary']['fleet_api']}\n" +
                f"- LangGraph API: {check_result['summary']['langgraph_api']}\n" +
                f"- LLM: {check_result['summary']['llm']}\n" +
                f"- æ•´ä½“çŠ¶æ€: {check_result['summary']['overall']}",
                metadata={"type": "api_tool_check", "result": check_result}
            )
            
        except Exception as e:
            logger.error(f"API/Tool check failed: {e}", exc_info=True)
    
    # ============================================
    # æ€§èƒ½æ£€æµ‹
    # ============================================
    
    async def _performance_test_task(self):
        """æ€§èƒ½æ£€æµ‹ä»»åŠ¡ï¼ˆ30åˆ†é’Ÿåé¦–æ¬¡ï¼Œä¹‹åæ¯30åˆ†é’Ÿï¼‰"""
        try:
            # é¦–æ¬¡ç­‰å¾…30åˆ†é’Ÿ
            logger.info("â° Performance test scheduled in 30 minutes...")
            await asyncio.sleep(1800)  # 30åˆ†é’Ÿ
            
            while True:
                try:
                    logger.info("=" * 80)
                    logger.info("ğŸ“Š Performance Test")
                    logger.info("=" * 80)
                    
                    await self._run_performance_test()
                    
                    logger.info("=" * 80)
                    logger.info(f"âœ… Performance Test Complete at {datetime.now().strftime('%H:%M:%S')}")
                    logger.info("=" * 80)
                    
                except Exception as e:
                    logger.error(f"Performance test failed: {e}")
                
                # ç­‰å¾…30åˆ†é’Ÿ
                await asyncio.sleep(1800)
                
        except asyncio.CancelledError:
            logger.info("Performance test task cancelled")
    
    async def _run_performance_test(self):
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        test_result = {
            "timestamp": datetime.now().isoformat(),
            "model_performance": {},
            "memory_status": {}
        }
        
        try:
            # 1. æµ‹è¯•LLMæ€§èƒ½
            logger.info("ğŸ¤– Testing LLM performance...")
            llm_base_url = os.getenv("LLM_BASE_URL", "http://192.168.9.125:8000/v1")
            
            try:
                # è·å–å½“å‰æ¨¡å‹
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(f"{llm_base_url}/models")
                    data = response.json()
                    models = data.get("data", [])
                    current_model = models[0].get("id") if models else None
                
                if current_model:
                    # æµ‹è¯•TTFTå’Œååé‡
                    test_prompt = "ä½ å¥½"
                    start_time = time.time()
                    ttft = None
                    
                    async with httpx.AsyncClient(timeout=30.0) as client:
                        async with client.stream(
                            "POST",
                            f"{llm_base_url}/chat/completions",
                            json={
                                "model": current_model,
                                "messages": [{"role": "user", "content": test_prompt}],
                                "max_tokens": 50,
                                "stream": True
                            }
                        ) as response:
                            first_chunk = True
                            async for line in response.aiter_lines():
                                if first_chunk and line.strip():
                                    ttft = (time.time() - start_time) * 1000
                                    first_chunk = False
                    
                    end_time = time.time()
                    total_latency = (end_time - start_time) * 1000
                    
                    # è·å–tokenç»Ÿè®¡
                    async with httpx.AsyncClient(timeout=30.0) as client:
                        response = await client.post(
                            f"{llm_base_url}/chat/completions",
                            json={
                                "model": current_model,
                                "messages": [{"role": "user", "content": test_prompt}],
                                "max_tokens": 50
                            }
                        )
                        data = response.json()
                        usage = data.get("usage", {})
                        completion_tokens = usage.get("completion_tokens", 0)
                    
                    tokens_per_second = round(completion_tokens / (total_latency / 1000), 2) if total_latency > 0 else 0
                    
                    test_result["model_performance"] = {
                        "model": current_model,
                        "tokens_per_second": tokens_per_second,
                        "ttft_ms": round(ttft, 2) if ttft else 0,
                        "total_latency_ms": round(total_latency, 2),
                        "status": "ok"
                    }
                    
                    logger.info(f"   âœ… {current_model}: {tokens_per_second} tok/s, TTFT: {ttft:.2f}ms")
                else:
                    test_result["model_performance"] = {"status": "no_model"}
                    logger.warning("   âš ï¸ No model loaded")
                    
            except Exception as e:
                test_result["model_performance"] = {"status": "error", "error": str(e)}
                logger.warning(f"   âŒ LLM performance test failed: {e}")
            
            # 2. æ£€æŸ¥å†…å­˜çŠ¶æ€
            logger.info("ğŸ’¾ Checking memory status...")
            try:
                import psutil
                process = psutil.Process()
                memory_info = process.memory_info()
                
                test_result["memory_status"] = {
                    "rss_mb": round(memory_info.rss / 1024 / 1024, 2),
                    "vms_mb": round(memory_info.vms / 1024 / 1024, 2),
                    "percent": round(process.memory_percent(), 2)
                }
                
                logger.info(f"   âœ… Memory: {test_result['memory_status']['rss_mb']} MB RSS")
            except Exception as e:
                test_result["memory_status"] = {"error": str(e)}
                logger.warning(f"   âš ï¸ Memory check failed: {e}")
            
            self.last_performance_test = test_result
            
            # æ¨é€åˆ°èŠå¤©å®¤å’Œæ§åˆ¶é¢æ¿
            perf = test_result.get("model_performance", {})
            mem = test_result.get("memory_status", {})
            
            await self._send_system_message(
                "ğŸ“Š æ€§èƒ½æµ‹è¯•å®Œæˆ\n" +
                f"- æ¨¡å‹: {perf.get('model', 'N/A')}\n" +
                f"- ååé‡: {perf.get('tokens_per_second', 0)} tok/s\n" +
                f"- TTFT: {perf.get('ttft_ms', 0)} ms\n" +
                f"- å†…å­˜: {mem.get('rss_mb', 0)} MB",
                metadata={"type": "performance_test", "result": test_result}
            )
            
        except Exception as e:
            logger.error(f"Performance test failed: {e}", exc_info=True)
    
    # ============================================
    # è¾…åŠ©æ–¹æ³•
    # ============================================
    
    async def _send_system_message(self, content: str, metadata: Dict = None):
        """å‘é€ç³»ç»Ÿæ¶ˆæ¯åˆ°èŠå¤©å®¤"""
        try:
            from backend.app.api.unified_chat_room import send_system_message
            await send_system_message(content, metadata)
        except Exception as e:
            logger.debug(f"Failed to send system message: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–åå°ä»»åŠ¡çŠ¶æ€"""
        uptime = time.time() - self.startup_time
        
        return {
            "started_at": self.started_at.isoformat(),
            "uptime_seconds": round(uptime, 2),
            "uptime_formatted": self._format_uptime(uptime),
            "preload_completed": self.preload_completed,
            "preload_time": self.preload_time.isoformat() if self.preload_time else None,
            "last_api_check": self.last_api_check["timestamp"] if self.last_api_check else None,
            "last_performance_test": self.last_performance_test["timestamp"] if self.last_performance_test else None,
            "health_status": self.health_status,
            "tasks": {
                name: "running" if not task.done() else "completed"
                for name, task in self.tasks.items()
            }
        }
    
    def _format_uptime(self, seconds: float) -> str:
        """æ ¼å¼åŒ–è¿è¡Œæ—¶é—´"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours}h {minutes}m {secs}s"


# å…¨å±€å®ä¾‹
background_tasks_manager = BackgroundTasksManager()
