"""
èŠå¤©å®¤SSEæµå¼API
ä¸ºèŠå¤©å®¤å‰ç«¯æä¾›/api/chat/streamç«¯ç‚¹
"""
from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Dict, Any
import json
import asyncio
from datetime import datetime
from langchain_core.messages import HumanMessage

from app.state import state_manager
from app.config import MAX_CONTEXT_LENGTH, COMPRESSION_TRIGGER_TOKENS

router = APIRouter()


class ChatRequest(BaseModel):
    message: str
    thread_id: str = "default_session"
    source: str = "user"
    metadata: Dict[str, Any] = {}


@router.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    SSEæµå¼èŠå¤©ç«¯ç‚¹
    å‰ç«¯é€šè¿‡EventSourceè¿æ¥æ­¤ç«¯ç‚¹
    """
    async def event_generator():
        try:
            # ä»å…¨å±€çŠ¶æ€è·å–app_graph
            app_graph = state_manager.get_app_graph()
            
            if not app_graph:
                # å¦‚æœworkflowæœªåˆå§‹åŒ–,è¿”å›é”™è¯¯
                yield f"data: {json.dumps({'type': 'error', 'message': 'Agentæœªåˆå§‹åŒ–,è¯·ç­‰å¾…å¯åŠ¨å®Œæˆ'})}\n\n"
                return
            
            # å‘é€å¼€å§‹äº‹ä»¶
            yield f"data: {json.dumps({'type': 'start', 'timestamp': datetime.now().isoformat()})}\n\n"
            
            # æ„é€ è¾“å…¥
            input_data = {
                "messages": [HumanMessage(content=request.message)]
            }
            
            # é…ç½®(åŒ…å«thread_idç”¨äºä¼šè¯ç®¡ç†)
            config = {
                "configurable": {
                    "thread_id": request.thread_id
                }
            }
            
            # æµå¼æ‰§è¡Œworkflow
            async for event in app_graph.astream(input_data, config=config):
                # å‘é€ä¸­é—´ç»“æœ
                if "agent" in event:
                    messages = event["agent"].get("messages", [])
                    if messages:
                        last_message = messages[-1]
                        
                        # å¦‚æœæ˜¯AIæ¶ˆæ¯
                        if hasattr(last_message, "content") and last_message.content:
                            yield f"data: {json.dumps({'type': 'message', 'content': last_message.content})}\n\n"
                        
                        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨
                        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                            for tool_call in last_message.tool_calls:
                                yield f"data: {json.dumps({'type': 'tool_call', 'tool': tool_call.get('name'), 'args': tool_call.get('args')})}\n\n"
                
                # å¦‚æœæœ‰å·¥å…·ç»“æœ
                if "tools" in event:
                    messages = event["tools"].get("messages", [])
                    if messages:
                        for msg in messages:
                            if hasattr(msg, "content"):
                                yield f"data: {json.dumps({'type': 'tool_result', 'content': str(msg.content)[:500]})}\n\n"  # é™åˆ¶é•¿åº¦
                
                # çŸ­æš‚å»¶è¿Ÿ,é¿å…è¿‡å¿«
                await asyncio.sleep(0.01)
            
            # å‘é€ç»“æŸäº‹ä»¶
            yield f"data: {json.dumps({'type': 'end', 'timestamp': datetime.now().isoformat()})}\n\n"
            
        except Exception as e:
            # å‘é€é”™è¯¯äº‹ä»¶
            error_msg = f"èŠå¤©å¤„ç†é”™è¯¯: {str(e)}"
            print(f"ERROR: {error_msg}")
            yield f"data: {json.dumps({'type': 'error', 'message': error_msg})}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨nginxç¼“å†²
        }
    )


@router.get("/api/chat/health")
async def chat_health():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "tools_loaded": state_manager.tool_pool_loaded,
        "app_graph_loaded": state_manager.app_graph is not None,
        "timestamp": datetime.now().isoformat()
    }


@router.get("/api/chat/context_stats")
async def get_context_stats():
    """è·å–ä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯"""
    stats = state_manager.get_context_stats()
    
    # è®¡ç®—ä½¿ç”¨ç‡
    current_tokens = stats.get("current_tokens", 0)
    usage_percent = (current_tokens / MAX_CONTEXT_LENGTH * 100) if MAX_CONTEXT_LENGTH > 0 else 0
    
    # ç¡®å®šè®°å¿†çŠ¶æ€
    compression_count = stats.get("compression_count", 0)
    if compression_count == 0:
        memory_status = "ğŸŸ¢ å®Œç¾è®°å¿†"
    elif compression_count == 1:
        memory_status = "ğŸŸ¡ è½»åº¦å¤±å¿†"
    elif compression_count == 2:
        memory_status = "ğŸŸ  ä¸­åº¦å¤±å¿†(å»ºè®®é‡ç½®)"
    else:
        memory_status = "ğŸ”´ é‡åº¦å¤±å¿†(å¿…é¡»é‡ç½®)"
    
    return {
        "current_tokens": current_tokens,
        "max_tokens": MAX_CONTEXT_LENGTH,
        "compression_threshold": COMPRESSION_TRIGGER_TOKENS,
        "usage_percent": round(usage_percent, 2),
        "compression_count": compression_count,
        "memory_status": memory_status,
        "last_compression_time": stats.get("last_compression_time")
    }
